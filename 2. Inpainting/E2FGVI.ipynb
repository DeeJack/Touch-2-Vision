{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZurXfq-F6jj"
   },
   "source": [
    "# Towards An <strong>E</strong>nd-to-<strong>E</strong>nd Framework for <strong>F</strong>low-<strong>G</strong>uided <strong>V</strong>ideo <strong>I</strong>npainting (CVPR 2022)\n",
    "\n",
    "In this demo, you can try to inpaint an example video through our framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDNKrW-NipaV"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4nBXDYiE-Y9",
    "outputId": "ec4e490f-029c-4b08-d19d-d765a2c9ffe9"
   },
   "outputs": [],
   "source": [
    "#@title Setup environment and code (may take some time)\n",
    "\n",
    "# Install Pytorch\n",
    "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# Install MMCV\n",
    "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.5/index.html\n",
    "\n",
    "# prepare code\n",
    "import os\n",
    "CODE_DIR = 'E2FGVI'\n",
    "os.makedirs(f'./{CODE_DIR}')\n",
    "!git clone https://github.com/MCG-NKU/E2FGVI.git $CODE_DIR\n",
    "os.chdir(f'./{CODE_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbTtlHMtLih_",
    "outputId": "6732b74d-13ae-4337-f507-4882d6a57a7e"
   },
   "outputs": [],
   "source": [
    "#@title Download model with PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import os\n",
    "\n",
    "download_with_pydrive = True\n",
    "\n",
    "class Downloader(object):\n",
    "    def __init__(self, use_pydrive):\n",
    "        self.use_pydrive = use_pydrive\n",
    "        current_directory = os.getcwd()\n",
    "        self.save_dir = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"release_model\")\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "        if self.use_pydrive:\n",
    "            self.authenticate()\n",
    "\n",
    "    def authenticate(self):\n",
    "        auth.authenticate_user()\n",
    "        gauth = GoogleAuth()\n",
    "        gauth.credentials = GoogleCredentials.get_application_default()\n",
    "        self.drive = GoogleDrive(gauth)\n",
    "\n",
    "    def download_file(self, file_id, file_name):\n",
    "        file_dst = f'{self.save_dir}/{file_name}'\n",
    "        if os.path.exists(file_dst):\n",
    "            print(f'{file_name} already exists!')\n",
    "            return\n",
    "        downloaded = self.drive.CreateFile({'id':file_id})\n",
    "        downloaded.FetchMetadata(fetch_all=True)\n",
    "        downloaded.GetContentFile(file_dst)\n",
    "\n",
    "downloader = Downloader(download_with_pydrive)\n",
    "path = {\"id\": \"1tNJMTJ2gmWdIXJoHVi5-H504uImUiJW9\", \"name\": \"E2FGVI_CVPR22_models.zip\"}\n",
    "downloader.download_file(file_id=path[\"id\"], file_name=path[\"name\"])\n",
    "\n",
    "os.chdir(downloader.save_dir)\n",
    "!unzip E2FGVI_CVPR22_models.zip\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lv4fnTdaWe9K"
   },
   "source": [
    "# Define Utility Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXPgvlRvF7oc"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import importlib\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# rc('animation', html='jshtml')\n",
    "\n",
    "from core.utils import to_tensors\n",
    "\n",
    "\n",
    "# global variables\n",
    "w, h = 432, 240\n",
    "ref_length = 10  # ref_step\n",
    "num_ref = -1\n",
    "neighbor_stride = 5\n",
    "\n",
    "\n",
    "# sample reference frames from the whole video\n",
    "def get_ref_index(f, neighbor_ids, length):\n",
    "    ref_index = []\n",
    "    if num_ref == -1:\n",
    "        for i in range(0, length, ref_length):\n",
    "            if i not in neighbor_ids:\n",
    "                ref_index.append(i)\n",
    "    else:\n",
    "        start_idx = max(0, f - ref_length * (num_ref//2))\n",
    "        end_idx = min(length, f + ref_length * (num_ref//2))\n",
    "        for i in range(start_idx, end_idx+1, ref_length):\n",
    "            if i not in neighbor_ids:\n",
    "                if len(ref_index) > num_ref:\n",
    "                    break\n",
    "                ref_index.append(i)\n",
    "    return ref_index\n",
    "\n",
    "\n",
    "# read frame-wise masks\n",
    "def read_mask(mpath):\n",
    "    masks = []\n",
    "    mnames = os.listdir(mpath)\n",
    "    mnames.sort()\n",
    "    for mp in mnames:\n",
    "        m = Image.open(os.path.join(mpath, mp))\n",
    "        m = m.resize((w, h), Image.NEAREST)\n",
    "        m = np.array(m.convert('L'))\n",
    "        m = np.array(m > 0).astype(np.uint8)\n",
    "        m = cv2.dilate(m, cv2.getStructuringElement(\n",
    "            cv2.MORPH_CROSS, (3, 3)), iterations=4)\n",
    "        masks.append(Image.fromarray(m*255))\n",
    "    return masks\n",
    "\n",
    "\n",
    "#  read frames from video\n",
    "def read_frame_from_videos(video_path):\n",
    "    vname = video_path\n",
    "    frames = []\n",
    "    lst = os.listdir(vname)\n",
    "    lst.sort()\n",
    "    fr_lst = [vname+'/'+name for name in lst]\n",
    "    for fr in fr_lst:\n",
    "        image = cv2.imread(fr)\n",
    "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        frames.append(image.resize((w, h)))\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wA7CC871cDnb"
   },
   "source": [
    "# Inpainting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "c2fc768d4b13497a92a5b1b579cdfac7",
      "860d8f0644094eb9928c5c9e6563c0fe",
      "0ceae06858364b6280a7aa23ec2ba50f",
      "f9aa7f4cbbd947b399034d698cf4cce5",
      "10eb9469081143dc86593e653a11a6f3",
      "d74546a84a484d16be13849879c85129",
      "f00f20bcfc494b1f80bc5c70fcadb9af",
      "8de7e49602804fccb820ed0f22ea8dc3",
      "078ed707298340549079c1adac5622c4",
      "2737945c46944984be31c036172bed53",
      "2b26c1c0862042fb920fa889c890d524"
     ]
    },
    "id": "MFVXcD3COD7B",
    "outputId": "5cbfa9d3-c21d-4f58-80a5-6649cf7ef775"
   },
   "outputs": [],
   "source": [
    "# set up models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = importlib.import_module('model.e2fgvi')\n",
    "model = net.InpaintGenerator().to(device)\n",
    "ckpt_path = 'release_model/E2FGVI-CVPR22.pth'\n",
    "data = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(data)\n",
    "print(f'Loading model from: {ckpt_path}')\n",
    "model.eval()\n",
    "\n",
    "# prepare dataset\n",
    "video_path = 'examples/tennis'\n",
    "mask_path = 'examples/tennis_mask'\n",
    "print(f'Loading videos and masks from: {video_path}')\n",
    "frames = read_frame_from_videos(video_path)\n",
    "video_length = len(frames)\n",
    "imgs = to_tensors()(frames).unsqueeze(0) * 2 - 1\n",
    "frames = [np.array(f).astype(np.uint8) for f in frames]\n",
    "\n",
    "masks = read_mask(mask_path)\n",
    "binary_masks = [np.expand_dims((np.array(m) != 0).astype(np.uint8), 2)\n",
    "                for m in masks]\n",
    "masks = to_tensors()(masks).unsqueeze(0)\n",
    "imgs, masks = imgs.to(device), masks.to(device)\n",
    "comp_frames = [None] * video_length\n",
    "\n",
    "# completing holes by e2fgvi\n",
    "print(f'Start test...')\n",
    "for f in tqdm(range(0, video_length, neighbor_stride)):\n",
    "    neighbor_ids = [i for i in range(max(0, f-neighbor_stride), min(video_length, f+neighbor_stride+1))]\n",
    "    ref_ids = get_ref_index(f, neighbor_ids, video_length)\n",
    "    selected_imgs = imgs[:1, neighbor_ids+ref_ids, :, :, :]\n",
    "    selected_masks = masks[:1, neighbor_ids+ref_ids, :, :, :]\n",
    "    with torch.no_grad():\n",
    "        masked_imgs = selected_imgs*(1-selected_masks)\n",
    "        pred_img, _ = model(masked_imgs, len(neighbor_ids))\n",
    "\n",
    "        pred_img = (pred_img + 1) / 2\n",
    "        pred_img = pred_img.cpu().permute(0, 2, 3, 1).numpy() * 255\n",
    "        for i in range(len(neighbor_ids)):\n",
    "            idx = neighbor_ids[i]\n",
    "            img = np.array(pred_img[i]).astype(\n",
    "                np.uint8)*binary_masks[idx] + frames[idx] * (1-binary_masks[idx])\n",
    "            if comp_frames[idx] is None:\n",
    "                comp_frames[idx] = img\n",
    "            else:\n",
    "                comp_frames[idx] = comp_frames[idx].astype(\n",
    "                    np.float32)*0.5 + img.astype(np.float32)*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUt4uIY_biMg"
   },
   "source": [
    "## Show the inpainting video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "vkL4idywgySw",
    "outputId": "e4c5bc75-ba49-408c-e562-024000994019"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.axis('off'); ax1.set_title('Original Video')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.axis('off'); ax2.set_title('Our Result')\n",
    "imdata1 = ax1.imshow(frames[0])\n",
    "imdata2 = ax2.imshow(comp_frames[0].astype(np.uint8))\n",
    "\n",
    "def update(idx):\n",
    "    imdata1.set_data(frames[idx])\n",
    "    imdata2.set_data(comp_frames[idx].astype(np.uint8))\n",
    "\n",
    "fig.tight_layout()\n",
    "anim = animation.FuncAnimation(fig, update, frames=len(frames), interval=50)\n",
    "from IPython.display import HTML\n",
    "HTML(anim.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "touch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "078ed707298340549079c1adac5622c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ceae06858364b6280a7aa23ec2ba50f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8de7e49602804fccb820ed0f22ea8dc3",
      "max": 5770988,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_078ed707298340549079c1adac5622c4",
      "value": 5770988
     }
    },
    "10eb9469081143dc86593e653a11a6f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2737945c46944984be31c036172bed53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b26c1c0862042fb920fa889c890d524": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "860d8f0644094eb9928c5c9e6563c0fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d74546a84a484d16be13849879c85129",
      "placeholder": "​",
      "style": "IPY_MODEL_f00f20bcfc494b1f80bc5c70fcadb9af",
      "value": "100%"
     }
    },
    "8de7e49602804fccb820ed0f22ea8dc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2fc768d4b13497a92a5b1b579cdfac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_860d8f0644094eb9928c5c9e6563c0fe",
       "IPY_MODEL_0ceae06858364b6280a7aa23ec2ba50f",
       "IPY_MODEL_f9aa7f4cbbd947b399034d698cf4cce5"
      ],
      "layout": "IPY_MODEL_10eb9469081143dc86593e653a11a6f3"
     }
    },
    "d74546a84a484d16be13849879c85129": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f00f20bcfc494b1f80bc5c70fcadb9af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9aa7f4cbbd947b399034d698cf4cce5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2737945c46944984be31c036172bed53",
      "placeholder": "​",
      "style": "IPY_MODEL_2b26c1c0862042fb920fa889c890d524",
      "value": " 5.50M/5.50M [00:00&lt;00:00, 12.2MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
